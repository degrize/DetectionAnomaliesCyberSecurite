{
 "metadata": {
  "language_info": {
   "version": "3.6.1",
   "nbconvert_exporter": "python",
   "name": "python",
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   }
  },
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Motivation : \n",
    "Nous sommes un groupe d'élèves ingénieurs du cercle MIS de l'INP-HB. Notre projet consiste en la détection d'anomalies en cyber sécurité via une plateforme qui surveille les activités sur les réseaux informatiques et utilise des algorithmes d'apprentissage automatique pour détecter les activités suspectes. Nous avons entraîné notre modèle à identifier les schémas d'activité normaux, afin de pouvoir détecter rapidement les activités anormales qui pourraient signaler une attaque. Nous planifions d'alerter les analystes de sécurité en cas de détection d'anomalies\n",
    "\n",
    "# Algorithme implémenté :\n",
    "- Détection d'anomalies basée sur les clusters (K-mean)\n",
    "- Répartition des données en catégories puis Enveloppe Gaussienne/Elliptique sur chaque catégorie séparément\n",
    "- Chaîne de Markov\n",
    "- Forêt d'isolement\n",
    "- Une classe SVM\n",
    "- RNN (comparaison entre prédiction et réalité)"
   ],
   "metadata": {
    "_cell_guid": "3975a3a8-8d1d-458c-9c18-7deeccbbf205",
    "_execution_state": "idle",
    "_uuid": "05bef3a5fb05cc62c34cace91131b01c452cff01",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# libraries\n",
    "#%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "#from pyemma import msm # not available on Kaggle Kernel\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM"
   ],
   "metadata": {
    "_cell_guid": "5ac34a72-3992-448a-8ced-12bb329c40a7",
    "_execution_state": "idle",
    "_uuid": "1fd6aebed8495fb904ca1465245627cef301294d",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# some function for later\n",
    "\n",
    "# return Series of distance between each point and his distance with the closest centroid\n",
    "def getDistanceByPoint(data, model):\n",
    "    distance = pd.Series()\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.set_value(i, np.linalg.norm(Xa-Xb))\n",
    "    return distance\n",
    "\n",
    "# train markov model to get transition matrix\n",
    "def getTransitionMatrix (df):\n",
    "\tdf = np.array(df)\n",
    "\tmodel = msm.estimate_markov_model(df, 1)\n",
    "\treturn model.transition_matrix\n",
    "\n",
    "def markovAnomaly(df, windows_size, threshold):\n",
    "    transition_matrix = getTransitionMatrix(df)\n",
    "    real_threshold = threshold**windows_size\n",
    "    df_anomaly = []\n",
    "    for j in range(0, len(df)):\n",
    "        if (j < windows_size):\n",
    "            df_anomaly.append(0)\n",
    "        else:\n",
    "            sequence = df[j-windows_size:j]\n",
    "            sequence = sequence.reset_index(drop=True)\n",
    "            df_anomaly.append(anomalyElement(sequence, real_threshold, transition_matrix))\n",
    "    return df_anomaly"
   ],
   "metadata": {
    "_cell_guid": "828ca1cd-759b-4d8a-a592-eaf2ca691780",
    "_execution_state": "idle",
    "_uuid": "9eb06b06b146c9aa9533c1a78203dd1025d6e27e",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 Données\n",
    "## 1.1 Extraire les données\n",
    "L'ensemble de données provient de https://www.kaggle.com/boltzmannbrain/nab\n",
    "Dans realKnownCause/ambient_temperature_system_failure.csv"
   ],
   "metadata": {
    "_cell_guid": "3da6fa0d-ef0f-42d1-bd59-ee4fb3cfc2ab",
    "_execution_state": "idle",
    "_uuid": "7459b17ef14b51410807f57f36e887682f2cad33",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../input/realKnownCause/realKnownCause/ambient_temperature_system_failure.csv\")"
   ],
   "metadata": {
    "_cell_guid": "bcb68e2d-981d-403d-bfed-655e8a9bdc3c",
    "_execution_state": "idle",
    "_uuid": "e7d412858498c0da43c102f0ef1db787f1652374",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Understand data"
   ],
   "metadata": {
    "_cell_guid": "fc3bc10f-54df-44e2-b3a2-cc8b59717c01",
    "_execution_state": "idle",
    "_uuid": "44c55c1820894f40f650cba31a4723591315345d",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.info())"
   ],
   "metadata": {
    "_cell_guid": "6ce4bfe8-1d91-4172-830e-a760e1d63b1e",
    "_execution_state": "idle",
    "_uuid": "3927fcc620162f8a69100525f83d609cd7b589f4",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# vérifier le format et la fréquence de l'horodatage\n",
    "print(df['timestamp'].head(10))"
   ],
   "metadata": {
    "_cell_guid": "d5b77b21-3793-42ab-b291-11189be9071f",
    "_execution_state": "idle",
    "_uuid": "5ef1df3d1671939759548a4199fd05c17ec251e1",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# vérifier la température moyenne\n",
    "print(df['value'].mean())"
   ],
   "metadata": {
    "_cell_guid": "5b0e5bea-f11b-4f81-93fd-a817a6f9f579",
    "_execution_state": "idle",
    "_uuid": "899ad93b122b2144c304ff31f93568e183c32c6c",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# modifier le type de colonne d'horodatage pour le traçage\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "# changer les degrés Fahrenheit en °C (température moyenne = 71 -> Fahrenheit)\n",
    "df['value'] = (df['value'] - 32) * 5/9\n",
    "# tracer les données\n",
    "df.plot(x='timestamp', y='value')"
   ],
   "metadata": {
    "_cell_guid": "0395bd90-61f4-49db-b157-b58853afe2f8",
    "_execution_state": "idle",
    "_uuid": "d5e63d3da28366ddf2fbaa2653d75536332713dc",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Ingénierie des fonctionnalités\n",
    "Extraire quelques fonctionnalités utiles"
   ],
   "metadata": {
    "_cell_guid": "90075ebb-0f2e-4258-8901-03a25ce67172",
    "_execution_state": "idle",
    "_uuid": "c62e4d5f8bf8a855aab7bfa86273d731a5638b6d",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# les heures et si c'est la nuit ou le jour (7:00-22:00)\n",
    "df['hours'] = df['timestamp'].dt.hour\n",
    "df['daylight'] = ((df['hours'] >= 7) & (df['hours'] <= 22)).astype(int)"
   ],
   "metadata": {
    "_cell_guid": "e1d36c51-0d96-43c5-8a6c-9f26d7997788",
    "_execution_state": "idle",
    "_uuid": "a86baa1be987a4de8b4b192af475ab4fde077d82",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# le jour de la semaine (lundi=0, dimanche=6) et s'il s'agit d'un jour de week-end ou d'un jour de semaine.\n",
    "df['DayOfTheWeek'] = df['timestamp'].dt.dayofweek\n",
    "df['WeekDay'] = (df['DayOfTheWeek'] < 5).astype(int)\n",
    "# Une estimation de la population anormale du jeu de données (nécessaire pour plusieurs algorithmes)\n",
    "outliers_fraction = 0.01"
   ],
   "metadata": {
    "_cell_guid": "b5dc68e4-89b0-4248-853d-e00e5e9ef4e9",
    "_execution_state": "idle",
    "_uuid": "c3d4a71542f5080b5f87a27cf681f542a665a34c",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# temps avec int pour tracer facilement\n",
    "df['time_epoch'] = (df['timestamp'].astype(np.int64)/100000000000).astype(np.int64)"
   ],
   "metadata": {
    "_cell_guid": "14cd3d26-a411-47f8-9238-2794284e8c9b",
    "_execution_state": "idle",
    "_uuid": "189cd0890e09373ed847b258d1354bd6eae7bfd8",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# création de 4 catégories distinctes qui semblent utiles (week end/jour semaine & nuit/jour)\n",
    "df['categories'] = df['WeekDay']*2 + df['daylight']\n",
    "\n",
    "a = df.loc[df['categories'] == 0, 'value']\n",
    "b = df.loc[df['categories'] == 1, 'value']\n",
    "c = df.loc[df['categories'] == 2, 'value']\n",
    "d = df.loc[df['categories'] == 3, 'value']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "a_heights, a_bins = np.histogram(a)\n",
    "b_heights, b_bins = np.histogram(b, bins=a_bins)\n",
    "c_heights, c_bins = np.histogram(c, bins=a_bins)\n",
    "d_heights, d_bins = np.histogram(d, bins=a_bins)\n",
    "\n",
    "width = (a_bins[1] - a_bins[0])/6\n",
    "\n",
    "ax.bar(a_bins[:-1], a_heights*100/a.count(), width=width, facecolor='blue', label='WeekEndNight')\n",
    "ax.bar(b_bins[:-1]+width, (b_heights*100/b.count()), width=width, facecolor='green', label ='WeekEndLight')\n",
    "ax.bar(c_bins[:-1]+width*2, (c_heights*100/c.count()), width=width, facecolor='red', label ='WeekDayNight')\n",
    "ax.bar(d_bins[:-1]+width*3, (d_heights*100/d.count()), width=width, facecolor='black', label ='WeekDayLight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "0c5f5102-2122-41da-980d-c58c8438f190",
    "_execution_state": "idle",
    "_uuid": "60e1a0334d22e2c0c96ac279cc48c66f99b43248",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous pouvons voir que la température est plus stable pendant la journée du jour ouvrable.\n",
    "# 2 Modèles\n",
    "## 2.1 Grappe uniquement\n",
    "#### À utiliser pour les anomalies collectives (non ordonnées).\n",
    "\n",
    "Nous regroupons la combinaison habituelle de fonctionnalités. Les points éloignés du cluster sont des points avec une combinaison habituelle de caractéristiques. Nous considérons ces points comme des anomalies."
   ],
   "metadata": {
    "_cell_guid": "57fc7caa-fb96-491a-9857-3c6e58e8cade",
    "_execution_state": "idle",
    "_uuid": "3d980e3fcede78e8b9a3719cf3ad1da9ece24bff",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Prenez des fonctionnalités utiles et normalisez-les\n",
    "data = df[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "# réduire à 2 fonctionnalités importantes\n",
    "pca = PCA(n_components=2)\n",
    "data = pca.fit_transform(data)\n",
    "# standardiser ces 2 nouvelles fonctionnalités\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)"
   ],
   "metadata": {
    "_cell_guid": "01224c89-4372-4f8b-bfb8-d13eb4357264",
    "_execution_state": "idle",
    "_uuid": "7dfbf8b613b235120c39e11a8a87f3c5e90022e3",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# calculer avec un nombre différent de centroïdes pour voir le graphique de perte (méthode du coude)\n",
    "n_cluster = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data) for i in range(len(kmeans))]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_cluster, scores)\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "be39cb8b-bcc7-4288-95cb-8c95291a55ba",
    "_execution_state": "idle",
    "_uuid": "452855f2761685d48a0bf360f253ecd18fe379fa",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Pas clair pour moi, je choisis arbitrairement 15 centroïdes et ajoute ces données à la trame de données centrale\n",
    "df['cluster'] = kmeans[14].predict(data)\n",
    "df['principal_feature1'] = data[0]\n",
    "df['principal_feature2'] = data[1]\n",
    "df['cluster'].value_counts()"
   ],
   "metadata": {
    "_cell_guid": "69beec11-d424-4646-b964-d5fbbf8a6550",
    "_execution_state": "idle",
    "_uuid": "0736ab2c718cbc4138b07deef6c20a690dcecdc7",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# tracer les différents clusters avec les 2 caractéristiques principales\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0:'red', 1:'blue', 2:'green', 3:'pink', 4:'black', 5:'orange', 6:'cyan', 7:'yellow', 8:'brown', 9:'purple', 10:'white', 11: 'grey', 12:'lightblue', 13:'lightgreen', 14: 'darkgrey'}\n",
    "ax.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"cluster\"].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "d14ac727-eac4-4ae1-99c8-b9fb9b1301e7",
    "_execution_state": "idle",
    "_uuid": "64ac4322fbf2bc36539e0a60ff8e45254dc63afe",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# obtenir la distance entre chaque point et son centre de gravité le plus proche. Les plus grandes distances sont considérées comme des anomalies\n",
    "distance = getDistanceByPoint(data, kmeans[14])\n",
    "number_of_outliers = int(outliers_fraction*len(distance))\n",
    "threshold = distance.nlargest(number_of_outliers).min()\n",
    "# anomaly21 contient le résultat d'anomalie de la méthode 2.1 Cluster (0 : normal, 1 : anomalie)\n",
    "df['anomaly21'] = (distance >= threshold).astype(int)"
   ],
   "metadata": {
    "_cell_guid": "cd260641-7e32-4305-b7a8-008fcff4dcfc",
    "_execution_state": "idle",
    "_uuid": "1a84160cfb1d419c3a0a57530c079bfa6b1a11b1",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation de l'anomalie avec la vue cluster\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0:'blue', 1:'red'}\n",
    "ax.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"anomaly21\"].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "38a6fd23-954f-400c-8065-f4bea22183d5",
    "_execution_state": "idle",
    "_uuid": "40e05059a9a66b52fba53c654232a356df3a8828",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation de l'anomalie dans le temps (viz 1)fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly21'] == 1, ['time_epoch', 'value']] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "56a2455c-ee60-491e-8010-aab56eeb8e3f",
    "_execution_state": "idle",
    "_uuid": "8ae64bd8c8b942e2b8aaf9e6b75d40df7b5c4c6c",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation d'anomalie avec répartition de température (viz 2)\n",
    "a = df.loc[df['anomaly21'] == 0, 'value']\n",
    "b = df.loc[df['anomaly21'] == 1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "9926f2fb-6fa2-44e8-8b97-c5e4b6de311f",
    "_execution_state": "idle",
    "_uuid": "3b12e1fe4c788500c1734de1c676dd4f429afe7c",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "La méthode de cluster détecte la basse température autour de la fin de l'enregistrement comme anormalement basse. Il ne détecte pas la température la plus élevée.\n",
    "## 2.2 Catégories + Gaussien\n",
    "#### À utiliser pour les données contextuelles et les anomalies collectives (non ordonnées).\n",
    "Nous séparerons les données par (ce que nous pensons) des catégories importantes. Ou nous pouvons séparer les données en fonction de différents clusters (méthode 2.3). Ensuite, nous trouvons des valeurs aberrantes (répartition gaussienne, unimodale) par catégories indépendamment."
   ],
   "metadata": {
    "_cell_guid": "211bffc8-1a4e-4e47-87af-2c50dd896d02",
    "_execution_state": "idle",
    "_uuid": "c7840c929e610cd29d1775e30ad45364407dc7a0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# creation of 4 differents data set based on categories defined before\n",
    "df_class0 = df.loc[df['categories'] == 0, 'value']\n",
    "df_class1 = df.loc[df['categories'] == 1, 'value']\n",
    "df_class2 = df.loc[df['categories'] == 2, 'value']\n",
    "df_class3 = df.loc[df['categories'] == 3, 'value']"
   ],
   "metadata": {
    "_cell_guid": "46755793-473d-413d-a0fc-b08b7d589676",
    "_execution_state": "idle",
    "_uuid": "0c35172a17989a3cf536fca25a4560a933eaa374",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# tracer la répartition de la température par catégories\n",
    "fig, axs = plt.subplots(2,2)\n",
    "df_class0.hist(ax=axs[0,0],bins=32)\n",
    "df_class1.hist(ax=axs[0,1],bins=32)\n",
    "df_class2.hist(ax=axs[1,0],bins=32)\n",
    "df_class3.hist(ax=axs[1,1],bins=32)"
   ],
   "metadata": {
    "_cell_guid": "1b973d0e-300a-4875-834d-d6011b43d25f",
    "_execution_state": "idle",
    "_uuid": "8562a05945620307d0a63ccd36da46e5c4434a3c",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# appliquer ellipticEnvelope (distribution gaussienne) à chaque catégorie\n",
    "envelope =  EllipticEnvelope(contamination = outliers_fraction) \n",
    "X_train = df_class0.values.reshape(-1,1)\n",
    "envelope.fit(X_train)\n",
    "df_class0 = pd.DataFrame(df_class0)\n",
    "df_class0['deviation'] = envelope.decision_function(X_train)\n",
    "df_class0['anomaly'] = envelope.predict(X_train)\n",
    "\n",
    "envelope =  EllipticEnvelope(contamination = outliers_fraction) \n",
    "X_train = df_class1.values.reshape(-1,1)\n",
    "envelope.fit(X_train)\n",
    "df_class1 = pd.DataFrame(df_class1)\n",
    "df_class1['deviation'] = envelope.decision_function(X_train)\n",
    "df_class1['anomaly'] = envelope.predict(X_train)\n",
    "\n",
    "envelope =  EllipticEnvelope(contamination = outliers_fraction) \n",
    "X_train = df_class2.values.reshape(-1,1)\n",
    "envelope.fit(X_train)\n",
    "df_class2 = pd.DataFrame(df_class2)\n",
    "df_class2['deviation'] = envelope.decision_function(X_train)\n",
    "df_class2['anomaly'] = envelope.predict(X_train)\n",
    "\n",
    "envelope =  EllipticEnvelope(contamination = outliers_fraction) \n",
    "X_train = df_class3.values.reshape(-1,1)\n",
    "envelope.fit(X_train)\n",
    "df_class3 = pd.DataFrame(df_class3)\n",
    "df_class3['deviation'] = envelope.decision_function(X_train)\n",
    "df_class3['anomaly'] = envelope.predict(X_train)"
   ],
   "metadata": {
    "_cell_guid": "f269fc3e-92da-470a-89ba-83cc51c07272",
    "_execution_state": "idle",
    "_uuid": "bbedf1d3f83cf7ae6b4ff65f979479a44b03bfe0",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# tracer la répartition de la température par catégories avec des anomalies\n",
    "a0 = df_class0.loc[df_class0['anomaly'] == 1, 'value']\n",
    "b0 = df_class0.loc[df_class0['anomaly'] == -1, 'value']\n",
    "\n",
    "a1 = df_class1.loc[df_class1['anomaly'] == 1, 'value']\n",
    "b1 = df_class1.loc[df_class1['anomaly'] == -1, 'value']\n",
    "\n",
    "a2 = df_class2.loc[df_class2['anomaly'] == 1, 'value']\n",
    "b2 = df_class2.loc[df_class2['anomaly'] == -1, 'value']\n",
    "\n",
    "a3 = df_class3.loc[df_class3['anomaly'] == 1, 'value']\n",
    "b3 = df_class3.loc[df_class3['anomaly'] == -1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0,0].hist([a0,b0], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "axs[0,1].hist([a1,b1], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "axs[1,0].hist([a2,b2], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "axs[1,1].hist([a3,b3], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "axs[0,0].set_title(\"WeekEndNight\")\n",
    "axs[0,1].set_title(\"WeekEndLight\")\n",
    "axs[1,0].set_title(\"WeekDayNight\")\n",
    "axs[1,1].set_title(\"WeekDayLight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "b309d1b4-3bfe-4803-85c0-f03b71bb00fc",
    "_execution_state": "idle",
    "_uuid": "f622f36a8c6d0d1abfde310cf25a0ff5ddba1c78",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ajouter les données à la main\n",
    "df_class = pd.concat([df_class0, df_class1, df_class2, df_class3])\n",
    "df['anomaly22'] = df_class['anomaly']\n",
    "df['anomaly22'] = np.array(df['anomaly22'] == -1).astype(int) "
   ],
   "metadata": {
    "_cell_guid": "771633b5-7924-4f98-9a9e-66dff0d8fb1e",
    "_execution_state": "idle",
    "_uuid": "250cab346e794bbdf6b3860e8880bb2c13d5a270",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation de l'anomalie dans le temps (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly22'] == 1, ('time_epoch', 'value')] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "ea6efd5d-014d-4257-9522-5f2560f9a7df",
    "_execution_state": "idle",
    "_uuid": "533cd11f31bc2ad2b2381b38a3ee722566ddb195",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation d'anomalie avec répartition de température (viz 2)\n",
    "a = df.loc[df['anomaly22'] == 0, 'value']\n",
    "b = df.loc[df['anomaly22'] == 1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "9bdd7add-99b4-42c6-9d3f-3670b9f9ebcf",
    "_execution_state": "idle",
    "_uuid": "0642b30ee151c600f5d9141a1b36b69cbd328a2c",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "De bonnes détections de valeurs extrêmes et une séparation de contexte ajoutent une certaine précision à la détection.\n",
    "## 2.3 Cluster+Gaussien\n",
    "Similaire à la solution 2.2 mais avec un cluster pour séparer les données dans différents groupes."
   ],
   "metadata": {
    "_cell_guid": "55a0778e-3606-4ce1-847c-06c148c55fb5",
    "_execution_state": "idle",
    "_uuid": "033a39b8f36b5089417199aeb21e37242cff0403",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Chaînes de Markov\n",
    "#### À utiliser pour les anomalies séquentielles (ordonnées)\n",
    "Nous devons discrétiser les points de données dans des états définis pour la chaîne de Markov. Nous prendrons juste 'valeur' ​​pour définir l'état de cet exemple et définirons 5 niveaux de valeur (très bas, bas, moyen, haut, très haut)/(VL, L, A, H, VH).\n",
    "La chaîne de Markov calculera la probabilité de séquence comme (VL, L, L, A, A, L, A). Si la probability is very weak we consider the sequence as an anomaly."
   ],
   "metadata": {
    "_cell_guid": "e966a2b5-b49d-489b-bb8f-88eff97deb6d",
    "_execution_state": "idle",
    "_uuid": "f796a11f0beacf7b60b9c02118f4517a0597cbff",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# définition de l'état différent\n",
    "x1 = (df['value'] <=18).astype(int)\n",
    "x2= ((df['value'] > 18) & (df['value']<=21)).astype(int)\n",
    "x3 = ((df['value'] > 21) & (df['value']<=24)).astype(int)\n",
    "x4 = ((df['value'] > 24) & (df['value']<=27)).astype(int)\n",
    "x5 = (df['value'] >27).astype(int)\n",
    "df_mm = x1 + 2*x2 + 3*x3 + 4*x4 + 5*x5\n",
    "\n",
    "# obtenir les étiquettes d'anomalie pour notre ensemble de données (évaluation de la séquence de 5 valeurs et anomalie = moins de 20 % de probabilité)\n",
    "# J'UTILISE pyemma NON DISPONIBLE DANS KAGGLE KERNEL\n",
    "#df_anomaly = markovAnomaly(df_mm, 5, 0.20)\n",
    "#df_anomaly = pd.Series(df_anomaly)\n",
    "#print(df_anomaly.value_counts())"
   ],
   "metadata": {
    "_cell_guid": "02d2db70-197e-4fc2-b027-b20f8565c463",
    "_execution_state": "idle",
    "_uuid": "f54f23f37f06672cb19d89765a6cbfadcbe32369",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "# add the data to the main \n",
    "df['anomaly24'] = df_anomaly\n",
    "\n",
    "# visualisation of anomaly throughout time (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly24'] == 1, ('time_epoch', 'value')] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "metadata": {
    "_cell_guid": "20f432e1-f393-4bc3-8d2d-32e4397e58a1",
    "_execution_state": "idle",
    "_uuid": "972ce803b0a56160d465e6c1f6ff0ddb9d564d85",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "# visualisation of anomaly with temperature repartition (viz 2)\n",
    "a = df.loc[df['anomaly24'] == 0, 'value']\n",
    "b = df.loc[df['anomaly24'] == 1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "metadata": {
    "_cell_guid": "c92f059a-7938-43f7-8d2d-426f772bae84",
    "_execution_state": "idle",
    "_uuid": "a73dbcfb3d0cddbde36fbd1dbc5a2a45e69f1262",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Détecter une séquence inhabituelle mais pas de valeur extrême. Plus difficile d'évaluer la pertinence sur cet exemple. La taille de la séquence (5) doit correspondre à un cycle intéressant.\n",
    "## 2.5 Forêt d'isolement\n",
    "#### À utiliser pour les anomalies collectives (non ordonnées).\n",
    "Simple, fonctionne bien avec différentes répartitions de données et efficace avec des données de grande dimension."
   ],
   "metadata": {
    "_cell_guid": "796a1096-dd90-4bfd-ba52-1fc3c0b99a16",
    "_execution_state": "idle",
    "_uuid": "2e6accac972f6adf0d907f458943ef5f2129e7df",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Prenez des fonctionnalités utiles et normalisez-les\n",
    "data = df[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "# train isolement forêt\n",
    "model =  IsolationForest(contamination = outliers_fraction)\n",
    "model.fit(data)\n",
    "# ajouter les données à la main\n",
    "df['anomaly25'] = pd.Series(model.predict(data))\n",
    "df['anomaly25'] = df['anomaly25'].map( {1: 0, -1: 1} )\n",
    "print(df['anomaly25'].value_counts())"
   ],
   "metadata": {
    "_cell_guid": "7b550505-0752-43a0-b21d-6dc0fd8105e2",
    "_execution_state": "idle",
    "_uuid": "0a5641fd4d56e1985f923a92f40138676a4fe54f",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation de l'anomalie dans le temps (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly25'] == 1, ['time_epoch', 'value']] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "34e8c98b-a99d-44f7-8aad-a599371b3703",
    "_execution_state": "idle",
    "_uuid": "f5ac7ddd6a6ac149c6e88664abc9fb5401756261",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation d'anomalie avec répartition de température (viz 2)\n",
    "a = df.loc[df['anomaly25'] == 0, 'value']\n",
    "b = df.loc[df['anomaly25'] == 1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'], label = ['normal', 'anomaly'])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "62a32613-6f21-46db-9212-0286be3d15dc",
    "_execution_state": "idle",
    "_uuid": "d4b909d1a62d7a5e2dd9f235d4fa31eb8d5a148f",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.6 Une classe SVM\n",
    "#### A utiliser pour les anomalies collectives (non ordonnées).\n",
    "Bon pour la détection de nouveauté (pas d'anomalies dans la rame). Cet algorithme fonctionne bien pour les données multimodales."
   ],
   "metadata": {
    "_cell_guid": "2c56928d-e7fa-4342-8bc5-23527ae69747",
    "_execution_state": "idle",
    "_uuid": "9c616d8efd272ea7aeddee0d8bb2a41d803209cd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Prenez des fonctionnalités utiles et normalisez-les\n",
    "data = df[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "# former une classe SVM\n",
    "model =  OneClassSVM(nu=0.95 * outliers_fraction) #nu=0.95 * outliers_fraction  + 0.05\n",
    "data = pd.DataFrame(np_scaled)\n",
    "model.fit(data)\n",
    "# ajouter les données à la main\n",
    "df['anomaly26'] = pd.Series(model.predict(data))\n",
    "df['anomaly26'] = df['anomaly26'].map( {1: 0, -1: 1} )\n",
    "print(df['anomaly26'].value_counts())"
   ],
   "metadata": {
    "_cell_guid": "16aea1c0-9a4c-489a-8b0c-b9e1893fba75",
    "_execution_state": "idle",
    "_uuid": "31b6408bed29fc271174502e699f12a3dd7deb9e",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation de l'anomalie dans le temps (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly26'] == 1, ['time_epoch', 'value']] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "c1ba12cb-4035-4082-9097-f9ebe4d5a550",
    "_execution_state": "idle",
    "_uuid": "a9cd247e4b1a081f538fe18305c98ed3e67429b3",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation d'anomalie avec répartition de température (viz 2)\n",
    "a = df.loc[df['anomaly26'] == 0, 'value']\n",
    "b = df.loc[df['anomaly26'] == 1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "71e58d95-e373-40b4-b7a7-f153b994fdc5",
    "_execution_state": "idle",
    "_uuid": "5fd47274d72716015023ef9ea94ae54befa056b7",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Donne un résultat similaire à la forêt d'isolement mais trouve quelques anomalies dans les valeurs moyennes. Difficile de savoir si c'est pertinent.\n",
    "## 2.7 RNN\n",
    "#### Utiliser pour les anomalies séquentielles (ordonnées)\n",
    "RNN apprend à reconnaître la séquence dans les données, puis à faire une prédiction basée sur la séquence précédente. Nous considérons une anomalie lorsque les prochains points de données sont éloignés de la prédiction RNN. L'agrégation, la taille de la séquence et la taille de la prédiction de l'anomalie sont des paramètres importants pour avoir une détection pertinente.\n",
    "Ici on fait apprendre à partir de 50 valeurs précédentes, et on prédit juste la 1 valeur suivante."
   ],
   "metadata": {
    "_cell_guid": "5b941a3a-1b7c-402a-9b3c-3de9cf50669b",
    "_execution_state": "idle",
    "_uuid": "379754b0742140516dde2963c36ea7db00139035",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#sélectionner et standardiser les données\n",
    "data_n = df[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data_n)\n",
    "data_n = pd.DataFrame(np_scaled)\n",
    "\n",
    "# paramètres importants et taille du train/test\n",
    "prediction_time = 1 \n",
    "testdatasize = 1000\n",
    "unroll_length = 50\n",
    "testdatacut = testdatasize + unroll_length  + 1\n",
    "\n",
    "#train data\n",
    "x_train = data_n[0:-prediction_time-testdatacut].as_matrix()\n",
    "y_train = data_n[prediction_time:-testdatacut  ][0].as_matrix()\n",
    "\n",
    "# test data\n",
    "x_test = data_n[0-testdatacut:-prediction_time].as_matrix()\n",
    "y_test = data_n[prediction_time-testdatacut:  ][0].as_matrix()"
   ],
   "metadata": {
    "_cell_guid": "dd04af3e-0b01-435a-b4fc-92666de95289",
    "_execution_state": "idle",
    "_uuid": "2fef8ac3eaa6116697b067f74be61a725898d784",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#unroll: créer une séquence de 50 points de données précédents pour chaque point de données\n",
    "def unroll(data,sequence_length=24):\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    return np.asarray(result)\n",
    "\n",
    "# adapter les jeux de données pour la forme des données de séquence\n",
    "x_train = unroll(x_train,unroll_length)\n",
    "x_test  = unroll(x_test,unroll_length)\n",
    "y_train = y_train[-x_train.shape[0]:]\n",
    "y_test  = y_test[-x_test.shape[0]:]\n",
    "\n",
    "# voir la forme\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ],
   "metadata": {
    "_cell_guid": "9ccb1c44-a714-45bd-8313-d6fc941bf220",
    "_execution_state": "idle",
    "_uuid": "be6f2d72557f6cb87179157efca44cdeab96b057",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# bibliothèques spécifiques pour RNN\n",
    "# keras est une couche haute construite sur la couche Tensorflow pour rester dans une mise en œuvre de haut niveau/facile\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import time #helper libraries\n",
    "from keras.models import model_from_json\n",
    "import sys"
   ],
   "metadata": {
    "_cell_guid": "9089b29d-a698-407d-8675-089a8641e153",
    "_execution_state": "idle",
    "_uuid": "d2d991c7cb9ab07c73b329e9cb7378d5dd2a3212",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Construire le modèle\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=x_train.shape[-1],\n",
    "    output_dim=50,\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    100,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    units=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "print('compilation time : {}'.format(time.time() - start))"
   ],
   "metadata": {
    "_cell_guid": "33166362-a1a8-4adb-a6fc-afb10cb8b1b4",
    "_execution_state": "idle",
    "_uuid": "bd87547d94e2d128a755c080e39386dfe642e8b8",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Former le modèle\n",
    "#nb_epoch = 350\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=3028,\n",
    "    nb_epoch=30,\n",
    "    validation_split=0.1)\n"
   ],
   "metadata": {
    "_cell_guid": "8e70774e-68d7-46ed-8434-edefc1db397f",
    "_execution_state": "busy",
    "_uuid": "5adb8e2b1b7d1f7d541b6b306b8d98885b37500a",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# enregistrer le modèle car la formation est longue (1h30) et on ne veut pas le faire à chaque fois\n",
    "\"\"\"\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\"\"\""
   ],
   "metadata": {
    "_cell_guid": "2f77488f-2a11-4abf-9d5d-28106b9b7543",
    "_execution_state": "idle",
    "_uuid": "53c665cfadb466197cdbd5c4390e37fd8bf9084e",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# charger json et créer un modèle\n",
    "\"\"\"\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\"\"\""
   ],
   "metadata": {
    "_cell_guid": "7f4b7842-5081-4f20-a082-d0f971949c34",
    "_execution_state": "idle",
    "_uuid": "db2f64492cc4929317153ecb4d0140f2f28c1e90",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# créer la liste des différences entre les données de prédiction et de test\n",
    "loaded_model = model\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = loaded_model.predict(x_test)\n",
    "# prédictions = lstm.predict_sequences_multiple(loaded_model, x_test, 50, 50)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))"
   ],
   "metadata": {
    "_cell_guid": "adb69c0d-ff41-49c5-bf30-335f85ef0ec5",
    "_execution_state": "idle",
    "_uuid": "f65429b7f2aed953e7db2c3276e4fcdd764df476",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# tracer la prédiction et la réalité (pour les données de test)\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(p,color='red', label='prediction')\n",
    "axs.plot(y_test,color='blue', label='y_test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "35249507-6673-4ac0-9196-b75f1cd5c395",
    "_execution_state": "idle",
    "_uuid": "2a0eb8a0ad91203f2797eb0602d6143bec46b96e",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sélectionner les points de données de prédiction/réalité les plus éloignés comme anomalies\n",
    "diff = pd.Series(diff)\n",
    "number_of_outliers = int(outliers_fraction*len(diff))\n",
    "threshold = diff.nlargest(number_of_outliers).min()\n",
    "# données avec étiquette d'anomalie (partie des données de test)\n",
    "test = (diff >= threshold).astype(int)\n",
    "# la partie données d'entraînement où on n'a rien prédit (surajustement possible) : pas d'anomalie\n",
    "complement = pd.Series(0, index=np.arange(len(data_n)-testdatasize))\n",
    "# # ajouter les données à la main\n",
    "df['anomaly27'] = complement.append(test, ignore_index='True')\n",
    "print(df['anomaly27'].value_counts())"
   ],
   "metadata": {
    "_cell_guid": "7011b0e3-e9b6-4ea0-bb0e-1c44b11ad950",
    "_execution_state": "idle",
    "_uuid": "0b6f73d8f09bdd06ced35203de4250807084122d",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation de l'anomalie dans le temps (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly27'] == 1, ['time_epoch', 'value']] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.axis([1.370*1e7, 1.405*1e7, 15,30])\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "c5230ec9-70cc-48de-aab0-b1f79c442a60",
    "_execution_state": "idle",
    "_uuid": "eea00d2cae4842b1ac445a8252844fb291905b4f",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# visualisation d'anomalie avec répartition de température (viz 2)\n",
    "a = df.loc[df['anomaly27'] == 0, 'value']\n",
    "b = df.loc[df['anomaly27'] == 1, 'value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "_cell_guid": "7ab6f44f-f316-406c-b72b-069fb1aa162f",
    "_execution_state": "idle",
    "_uuid": "4400b2bf187ba69b7616f19eee23bc2277c2d766",
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Anomalies collectives et séquentielles (Ordonnées)\n",
    "Cette classe est la plus générale et considère l'ordre ainsi que les combinaisons de valeurs. Nous utilisons généralement une combinaison d'algorithmes comme le modèle cluster + markov.\n",
    "## 3 Comparaison des résultats\n",
    "(peut-être plus tard)\n",
    "## 4 Conclusion\n",
    "Dans ce cas, la détection d'anomalies contextuelles (catégories+enveloppe elliptique) semble une bonne solution.\n"
   ],
   "metadata": {
    "_cell_guid": "43e8a0e9-63eb-462c-a08b-996cb27dfa5f",
    "_execution_state": "idle",
    "_uuid": "6a419593698fe1d6ef85deec4401b1767e7d4538",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}